[{"content":"馬可夫決策過程 強化學習(Reinforcement Learning, RL)藉由互動學習如何行動以實現目標，而馬可夫決策過程(Markov decision processes, MDPs)，是RL數學化的一種理想表示。MDPs中，代理(agent)與其環境(environment)在一連串分立的時步互動，其中代理是完全可知且可控的，而環境是不完全可控且很有可能難以理解的。代理與環境之互動遵循以下定義:\n代理選擇動作(action) 動作的選擇基於狀態(states) 選擇的驗證基於回饋(rewards) 策略(policy)定義代理在給定狀態$S_t$下如何選擇動作$A_t$，而代理的目標為最大化期望回饋$G_t$。\n$$G_t = R_{t+1}+R_{t+2}+R_{t+3}+\\dotsb+R_T$$ $T$為最終時步，該形式如果再$T$極大時令$G_t$發散至無窮，所以實務上會使用以下形式:\n$$ G_t = R_{t+1}+\\gamma R_{t+2}+\\gamma^2 R_{t+3}+\\dotsb=\\sum_{k=0}^{\\infty}\\gamma^kR_{t+k+1}, \\text{ in } 0 \\le \\gamma \\le 1 $$\n$\\gamma$為衰減係數。上式以遞迴形式表達:\n$$ \\begin{align*} G_t \u0026amp;= R_{t+1}+\\gamma R_{t+2}+\\gamma^2 R_{t+3}+\\dotsb \\newline \u0026amp;= R_{t+1}+\\gamma (R_{t+2}+\\gamma R_{t+3}+\\dotsb) \\newline \u0026amp;= R_{t+1}+\\gamma G_{t+1} \\end{align*} $$\n範例: $$ \\begin{align*} \\mathcal{S} \u0026amp;= \\set{ \\text{high}, \\text{low} } \\newline \\mathcal{R} \u0026amp;= \\set{ -3, 0, r_{\\text{wait}}, r_{\\text{search}} } \\newline \\mathcal{A(\\text{hight})} \u0026amp;= \\set{ \\text{search}, \\text{wait} } \\newline \\mathcal{A(\\text{low})} \u0026amp;= \\set{ \\text{search}, \\text{wait}, \\text{recharge} } \\newline \\end{align*} $$\nMDPs以表表示:\n以轉移機率圖表示:\n策略與價值函數 大部分的強化學習演算法需要價值函數，其估計代理在給定的狀態(或狀態-操作對)在未來的期望回饋總和，與策略有關。\n策略將狀態$S$映射為每個可能操作的機率，如果代理在時間$t$遵循策略$\\pi$，則$\\pi(a|s)$即為在狀態$S_t=s$下操作為$A_t=a$機率。\n策略$\\pi$的狀態-價值函數 :\n$$ \\begin{align*} v_{\\pi}(s) \u0026amp;= \\mathbb{E}{\\pi}[G_t|S_t=s] \\newline \u0026amp;= \\mathbb{E}{\\pi}[\\sum_{k=0}^{\\infty}\\gamma^kR_{t+k+1}|S_t=s], \\text{for all } s \\in \\mathcal{S} \\end{align*} $$\n策略$\\pi$的動作-價值函數 :\n$$ q_{\\pi}(s, a) = \\mathbb{E}{\\pi}[G_t|S_t=s, A_t=a] = \\mathbb{E}{\\pi}[\\sum_{k=0}^{\\infty}\\gamma^kR_{t+k+1}|S_t=s, A_t=a] $$\n最佳化策略和最佳化價值函數 解RL任務即為找一可以在長久運行下取得大量回饋的策略。\n","permalink":"https://lin-roger.github.io/posts/reinforcementlearning/","summary":"從馬可夫決策過程到雙重深度Q網路","title":"Reinforcement Learning"},{"content":"摘要 大語言模型(LLM)表現出優秀的語境內學習(ICL, in-context learning)的能力。為提升LLM的ICL能力，許多透過取得現有訓練語料中的有效示範(demonstration, 可以說是context)的方法被提出，但終端使用者在使用LLM時並不能存取訓練語料或demonstration pool。 該文提出一個簡單框架SELF-ICL實現零樣本ICL:\n給定一個測試輸入 利用指令引導模型產生多筆偽輸入 令模型預測偽輸入的偽標籤 以偽(輸入/標籤)作為ICL的context預測測試輸入的標籤 於23 BIG-Bench Hard tasks上的測試表明，SELF-ICL優於zero-shot的表現。此外，結合zero-shot CoT(chain-of-thought)，SELF-ICL的表現甚至比肩來自真實語料的示範。\n簡介 語境內學習(ICL, in-context learning), 透過指令給予少量範例(demonstrations, exemplars)使LLM適應新任務(即Few-shot learning)，是使LLM備受關注的的重要特性。為取得更好的ICL能力，選擇具代表性範例的方法被廣泛研究，大多方法假設可以存取外部大型資源(訓練資料集、相關文字語料)並以最鄰近搜尋或其他相似性度量從中選取範例。然而現實中，使用者查詢LLM通常透過API或網頁介面，無權訪問與任務相關的現有語料。由使用者自行為任務編寫範例也增加了使用者的負擔(費時費力)。\n近期一系列解釋ICL原理的研究被廣泛提出，表明範例之所以有效不是因其為新任務的學習提供明確引導，而是揭露LLM的隱含能力並引導模型貼近目標領域，相似現象也出現在CoT(chain-of-thought)和指令增強ICL(instruction-augmented ICL)。表明LLM具有被低估的零樣本能力且具備處理多樣目標任務的能力。\n受上述文獻啟發，作者提出SELF-ICL，透過自生成範例(提供ICL所需輸入與標籤之空間)引導LLM的隱含能力。給定一查詢(測試輸入)，SELF-ICL會執行以下步驟:\n利用指令引導模型依據給定查詢與相關任務陳述產生多筆偽輸入。 透過零樣本(zero-shot)指令為每筆偽輸入生成偽標籤。 以偽輸入-標籤對做為偽範例與給定查詢合併進行標準ICL。 所有步驟皆在同一凍結LLM執行，無須從候選池選擇範例，弭平現有技術與終端使用者的實務差距。\n為了於現存範例不易產生的困難任務驗證SELF-ICL的有效性，作者選擇 23 BIG-Bench Hard tasks 作為驗證資料。結果表明SELF-ICL在所有任務均有顯著提升(all-task-average accuracy and in head-to-head comparisons)，相較於zero-shot在23個任務中取得 18-0-5 (勝-平-敗) 的成績。且若結合zero-shot CoT(chain-of-thought)，SELF-ICL的表現甚至比肩來自真實語料的示範。\n該文額外驗證SELF-ICL在不同設定下的有效性，如:\n生成偽輸入的方法 number of shots 隨機偽標籤 據作者所知，該研究第一個嘗試真zero-shot ICL，無須依賴來自真實分部或預定義標籤集之現有資料。 (如下表)\nSELF-ICL 建構偽輸入(step 1) 偽輸入生成可以簡單透過零次指令(zero-shot prompting)達成(如下圖)\n給定查詢$q$(取自真實分布)提供實際輸入的輪廓，和相關的任務描述$T$指引模型產生任務領域相關的資訊。模型推理與淺在格式與產稱新的查詢(偽輸入)，在指定中給定$k$(num of shot)，以產生$k$個偽輸入。\n建構偽標籤(step 2) 取得偽輸入後，利用零次指令在同一LLM預測其偽標籤，使用兩種方法:\nDirect prompting\n利用標準零次指令直接產生偽標籤，僅向LLM提供任務描述與需生成偽標籤的偽輸入。一次一對。 CoT prompting\n$$觸發短語+推理過程+最終解=偽標籤$$\n利用zero-shot CoT產生偽標籤，向LLM提供任務描述、需生成偽標籤的偽輸入與觸發短語 \u0026ldquo;Let\u0026rsquo;s think step by step\u0026quot;執行CoT推理。觸發短語置於指令末端引導產生推理過程已得到更準確的最終解。 預測(step 3) 建構偽範例(偽輸入-標籤對)，以偽範例和指令做為語境，透過Few-shot ICL預測測試輸入的最終答案。\n實驗設計 Configurations LM\nInstructGPT(text-davinci-003): 主要測試對象，被社群認為更遵循指令\ntext-bison-001(PaLM-2): 次要測試對象，驗證方法是否普遍有效\ngpt-3.5-turbo-instruct(GPT-3.5, ChatGPT): 次要測試對象，驗證方法是否普遍有效\nImplementation details\n參數設置如下:\n$Temperature = 0$ $NumOfToken_{max} = 1024$ $k = 3$\n其他參數沿用官方預設\nDataset\nBIG-Bench Hard (BBH) benchmark\n共包含了27個任務，其中23個被選為測試任務，皆為單選題，每個任務有150~250的範例，全部共有5,511個。\nBBH為BIG-Bench benchmark中的一個任務套組，現有LM在該套組難以到達人類平均水平，被認為難度超越現有模型所擁有的能力。\nBaselines ZS-Direct\n即\u0026quot;zero-shot direct prompting\u0026rdquo;，direct prompting的Baselines，模型僅依據任務描述和測試輸入預測輸出\nZS-CoT\n即\u0026quot;zero-shot CoT prompting\u0026quot;，CoT prompting的Baselines，zero-shot解複雜推理任務的SOTA(之一，待確認)，模型依任務描述、測試輸入和推理觸發短語\u0026quot;Let\u0026rsquo;s think step by step\u0026quot;預測輸出\n結果 主要表現 $\\delta$ (delta 小寫) 為 SELF-ICL 和 Baseline 的差，正值為高於Baseline，負值為落後於Baseline。\n$\\dagger$ (dagger) 代表通過 one-sided McNemar\u0026rsquo;s test 確認相對於Baseline的性能增益具顯著性，$p \u0026lt; 0.05$。\nSELF-ICL 於所有任務的平均表現在Direct和CoT皆超越Baselines。 Direct SELF-ICL 微小超越 ZS-CoT。 CoT SELF-ICL 能力到達使用真實範例的 3-shot prompting 的水準。 Direct ZS vs SELF-ICL: | 18勝 | 0平 | 5敗 | CoT ZS vs SELF-ICL: | 16勝 | 2平 | 5敗 | SELF-ICL Direct vs CoT: | 14勝 | 1平 | 8敗 | 普遍性 分析 Preliminary 給定 k-shot 示範 : ${(x_1, y_1), \\dots, (x_k, y_k)}$，$x_i$為輸入，$y_i$為標籤。 建立示範需考慮以下四個面向：\n輸入-標籤 映射: $x_i$與$y_i$是否配對正確。(於標準ICL中非必要) 輸入空間: $x_1, \\dots, x_k$的潛在分布。 標籤空間: $y_1, \\dots, y_k$的所有可能標籤。 格式: $x_i$-$y_i$的表示格式。 The Entanglement of Input Space and Input-Label Mapping \u0026amp; Effect of Different Number of Shots Self-ICL 使用測試輸入生成偽示範，生成出的偽示範可能與測試輸入相似，無法完整表示輸入空間，且複製效應(模型傾向回答與測試輸入相似的演示)的影響可能會導致效能下降。\nDifferent Approaches for Generating Pseudo-Inputs 作者提出以下三種方法實驗複製效應的影響:\nBatch inference: 在同一個任務中使用不只一個測試輸入。 Prompting with diversity hints: 指令中要求模型生成\u0026quot;new\u0026quot;, \u0026ldquo;diverse\u0026rdquo;, \u0026ldquo;creative\u0026quot;的偽輸入。 Prompt without diversity hints: 指令不特別要求2所提的關鍵詞。(對照組) 不同方法的偽輸入與測試輸入語意相似度如下圖5。(越低複製效應的影響越小)。\n不同方法的效能如下圖6。(越高越好)\n由上兩張圖可知，增加偽輸入的多樣性可以增強ICL的效能。圖6可知，3-shot的表現最好，且比較0-shot與1-shot可知，僅增加一筆示範即可大幅增加模型表現，由此可知Self-ICL的有效性。\nEffect of Random Pseudo-Labels 參考圖6，將偽標籤隨機打亂的性能並不佳，但還是高過於0-shot。作者提出以下解釋：\n複製效應 模型將偽演示中的錯誤答案視為正確。 A Deeper Look of SELF-ICL\u0026rsquo;s Pseudo-Inputs 進一步比較真實演示和測試輸入的相似性與偽演示和測試輸入的相似性，如下圖7。\n相關文獻 Understanding ICL Towards Zero-Shot ICL 總結 侷限性 Reliance on instruction-following models Better diversify approaches ","permalink":"https://lin-roger.github.io/posts/selficlzeroshotincontextlearningwithselfgenerateddemonstrations/","summary":"A simple framework which bootstraps LMs\u0026rsquo; intrinsic capabilities to perform zero-shot ICL","title":"SELF-ICL: Zero-Shot In-Context Learning with Self-Generated Demonstrations"},{"content":"摘要 本章介紹推薦系統中常用的資料探勘(Data mining, DM)技術。首先描述的是常見的資料預處理方法，如抽樣與降維。接著回顧推薦系統中重要的分類/分群技術，如:貝葉斯網路和支援向量機(SVM)/k-mean。\n簡介 推薦系統可視為DM的一種特例，以下簡要回顧推薦系統常用的DM方法，DM通常有以下三步驟:\n1. 資料預處理 資料為一組物件(record, item, point, sample, observation, or instance)和屬性(variable, field, characteristic, or feature)的組合。資料通常須經預處理，以便後續分析使用，\n距離度量 衡量兩筆資料的差異性，不同技術須使用不同方法。\n$L_p$-dist $d(x, y) = (\\sum^n_{k = 1}|x_k-y_k|^p)^{\\frac{1}{p}}$\n$p = 1$，曼哈頓距離\n$p = 2$，歐式距離\n餘弦距離 $\\cos(x, y) = \\frac{x \\cdot y}{\\left |x\\right |^2 \\left |y\\right |^2}$\n計算兩向量間的夾角\n皮爾森相關係數 $Peason(x, y) = \\frac{\\mathbf{cov}(x, y)}{\\sigma_x \\times \\sigma_y}$\n計算$x, y$的關係。\n+1 代表$x, y$正相關\n-1 代表$x, y$負相關\n0 代表$x, y$間沒有明確關係\n單純一致係數(Simple Matching Coefficient, SMC)、Jaccard index $SMC = \\frac{\\mathbf{num\\ of\\ match}}{\\mathbf{num\\ of\\ attribute}} = \\frac{\\mathbf{M11+M00}}{\\mathbf{M01+M10+M00+M11}}$\n$\\mathbf{M00: x=0, y=0}$\n$\\mathbf{M10: x=1, y=0}$\n$\\mathbf{M01: x=0, y=1}$\n$\\mathbf{M11: x=1, y=1}$\n$Jaccard index = \\frac{\\mathbf{M11}}{\\mathbf{M01+M10+M11}}$\n$Jaccard index(bit\\ vector) = \\frac{x\\cdot y}{\\left |x\\right |^2 + \\left |y\\right |^2 - x \\cdot y}$\n抽樣 80/20法則: training $80%$ / testing $20%$。\nk-fold(k折交叉驗證): 將資料集拆為k份，在訓練時將其中一份作為testing，其餘作為training。\n降維 推薦系統利用使用者與項目間的的關係推算使用者可能喜歡的項目。然而使用者和項目的數量龐大且使用者通常只會與少量的向產生關係，所以這些資訊是稀疏(大部分都是0)且高維(但不同維度間有相關性，冗餘維度)的，需透過降維解決這些問題。\nPCA 將有相關性的維度合併，去除資訊中攏餘的維度。\nSVD 將原始資料矩陣$A$轉換為三個較小的矩陣$U\\Sigma V^\\top$表示。\nSVD推薦系統[1、2]\n2. 資料分析 分類 kNN: 離樣本$q$最近的$k$個點，他們屬於甚麼類別(取最多) 決策樹: C\u0026amp;RT(CART)、C4.5、ID3。 貝葉斯 ANN SVM 將多個分類器集成[8]可以取得更好的效果\n分群 k-means 總結 回顧推薦系統中常用的資料探勘技術，\nreference [1] SVD 實作推薦系統\n[2] SVD++ 與混合模型\n[3] SVD_推薦系統_原理\n[4] Machine Learning Foundations/Techniques: Decision Tree / Random Forest\n[5] [機器學習] MultinomialNB 貝氏(貝葉氏)分類-理論篇\n[6] Machine Learning Foundations/Techniques: Neural Networks and Matrix Factorization\n[7] Machine Learning Foundations/Techniques: Linear Support Vector Machine\n[8] Machine Learning Foundations/Techniques: Blending / Bagging / Boosting\n","permalink":"https://lin-roger.github.io/posts/dataminingmethodsforrecommendersystems/","summary":"推薦系統中的資料探勘方法。本章介紹推薦系統中常用的資料探勘(Data mining, DM)技術。首先描述的是常見的資料預處理方法，如抽樣與降維。接著回顧推薦系統中重要的分類/分群技術，如:貝葉斯網路和支援向量機(SVM)/k-mean。","title":"Recommender systems handbook || 閱讀紀錄 1. Data Mining Methods for Recommender Systems"},{"content":"推薦系統簡介 推薦系統的目的是向使用者提供有價值的項目(items)，例如商品、新聞和串流影片，以幫助他們在大量資訊中找到有價值的內容。我們通常研究的推薦系統是個人化的，根據個人或特定使用者群體的偏好調整推薦項目。相比之下，大眾化的推薦系統方法通常較容易實現，例如top10 熱門項目。儘管這種方法在特定情境下可能有效，但它並不是推薦系統主要討論的議題。個人化推薦最簡單的形式可以用一排序後的項目列表呈現(最有興趣-\u0026gt;最沒興趣)，系統透過使用者的偏好(對某項目的評分、是否查看某項目的詳細資訊)或某些條件排序。最早的推薦系統透過尋找和被推薦使用者(目標)相似的使用者，並將相似使用者關注或選擇的項目推薦給目標，該方法即為協同過濾(Collaborative filtering)。而現代人日常要接受的資訊繁多2，如何令使用者可以方便的取得有價值的資訊已成為重要問題，推薦系統很好的解決了此問題。\n更新計畫與週期 可能兩周一更\n本書架構 Part I Basic Techniques Data Mining Methods for Recommender Systems 🚧 Content-based Recommender Systems: State of the Art and Trends 🚧 A Comprehensive Survey of Neighborhood-based Recommendation Methods 🚧 Advances in Collaborative Filtering 🚧 Developing Constraint-based Recommenders 🚧 Context-Aware Recommender Systems 🚧 Part II Applications and Evaluation of RSs Evaluating Recommendation Systems 🚧 A Recommender System for an IPTV Service Provider: a Real Large-Scale Production Environment 🚧 How to Get the Recommender Out of the Lab? 🚧 Matching Recommendation Technologies and Domains 🚧 Recommender Systems in Technology Enhanced Learning 🚧 Part III Interacting with Recommender Systems On the Evolution of Critiquing Recommenders 🚧 Creating More Credible and Persuasive Recommender Systems: The Influence of Source Characteristics on Recommender System Evaluations 🚧 Designing and Evaluating Explanations for Recommender Systems 🚧 Usability Guidelines for Product Recommenders Based on Example Critiquing Research 🚧 Map Based Visualization of Product Catalogs 🚧 Part IV Recommender Systems and Communities Communities, Collaboration, and Recommender Systems in Personalized Web Search 🚧 Social Tagging Recommender Systems 🚧 Trust and Recommendations 🚧 Group Recommender Systems: Combining Individual Models 🚧 Part V Advanced Algorithms Aggregation of Preferences in Recommender Systems 🚧 Active Learning in Recommender Systems 🚧 Multi-Criteria Recommender Systems 🚧 Robust Collaborative Recommendation 🚧 reference [1] Wiki: Collaborative filtering\n[2] Wiki: Information overload\n","permalink":"https://lin-roger.github.io/posts/recommendersystemshandbook/","summary":"簡要說明推薦系統(RS)的基本概念，與此書的基本架構","title":"Recommender systems handbook || 閱讀紀錄 0.概述"},{"content":"Zero-Shot Prompting \u0026amp; Few(N)-Shot Prompting How it work Shot意指範例，顧名思義，Zero-Shot就是提示不包含任何範例，反之N-Shot就是提示包含N個範例，在簡單任務中您使用Zero-Shot Prompting通常也可獲得不錯的效果，但當問題開始複雜起來時，Few-Shot Prompting 可以更好的解決問題\nThe model has somehow learned how to perform the task by providing it with just one example (i.e., 1-shot). For more difficult tasks, we can experiment with increasing the demonstrations (e.g., 3-shot, 5-shot, 10-shot, etc.).\n模型通過僅提供一個示例（即 1-shot）以某種方式學會瞭如何執行任務。對於更困難的任務，我們可以嘗試增加演示次數（例如 3 次、5 次、10 次等）。\nFollowing the findings from Min et al. (2022), here are a few more tips about demonstrations/exemplars when doing few-shot:\n根據 Min 等人的研究結果，這裡有一些關於進行小樣本時演示/範例的更多提示：\n\u0026ldquo;the label space and the distribution of the input text specified by the demonstrations are both important (regardless of whether the labels are correct for individual inputs)\u0026rdquo;\n“演示指定的標籤空間和輸入文本的分佈都很重要（無論標籤對於各個輸入是否正確）”\nthe format you use also plays a key role in performance, even if you just use random labels, this is much better than no labels at all.\n您使用的格式對性能也起著關鍵作用，即使您只是使用隨機標籤，這也比根本沒有標籤要好得多。\nadditional results show that selecting random labels from a true distribution of labels (instead of a uniform distribution) also helps.\n其他結果表明，從真實的標籤分佈（而不是均勻分佈）中選擇隨機標籤也有幫助。\nLimitations 當問題牽扯到具有多步驟的複雜推裡時，Few(N)-Shot 的效果會減弱，這時將指令拆解會是更好的選擇\nChain-of-Thought Prompting Self-Consistency Generated Knowledge Prompting Tree of Thoughts (ToT) Retrieval Augmented Generation (RAG) Automatic Reasoning and Tool-use (ART) Automatic Prompt Engineer (APE) Active-Prompt Directional Stimulus Prompting ReAct Prompting Multimodal CoT Prompting Graph Prompts ","permalink":"https://lin-roger.github.io/posts/advancedpromptingengineering/","summary":"🚧目前進度:deepl部分翻譯🚧","title":"🚧Advanced Prompting Engineering 進階提示工程🚧"},{"content":"Base LLM \u0026amp; Instruction Tuned LLM Base LLM 使用大量從網路爬取的資料訓練，輸入一文本後預測出最有可能接續在該文本後的下一個字(token)，所以給定一文章的前半部分其可將其後半部分生成。問題 -\u0026gt; 最有可能接續的字詞和人類預想的相同嗎?假設以下為您的訓練資料\n常見問題:\nQ1:為什麼同樣行程不同旅行社價格會不一樣？\nQ2:行程上有的景點，是不是一定都會走到？\nQ3:為什麼我和朋友的座位沒有安排在一起？\nA1:其實旅遊產品牽涉範圍極廣\u0026hellip;\nA2:旅客在報名旅遊行程前\u0026hellip;\nA3:機上座位的安排\u0026hellip;\n當您向使用該資料訓練的LM輸入\u0026quot;Q1:為什麼同樣行程不同旅行社價格會不一樣？\u0026quot;，我們通常為期望LM回答與問題對應的答案，也就是:\u0026ldquo;A1:其實旅遊產品牽涉範圍極廣\u0026hellip;\u0026quot;，但實際上LM會回答:\u0026ldquo;Q2:行程上有的景點，是不是一定都會走到？\u0026quot;，這是因為資料集中，文本Q1的下一段文本為Q2，而非A1，使模型認為Q1-\u0026gt;Q2是最好的選擇，而非Q1-\u0026gt;A1。\n為解決此問題，Instruction Tuned LLM 出現了。透過對Base LLM 使用指令資料集(如: alpaca-tw )微調並使用RLHF技術使LM的的輸出更符合人類的預期。\n指令的基本原則 0. Model Limitations: Hallucination 幻覺(Hallucination)，LLM並不了解自身知識的極限也不完全記得所有其看過的資訊，遇到一些艱澀的問題其可能會嘗試回答，並輸出看似合理但與事實不符或錯誤的回應，透過要求模型找出問題相關的文獻並引用其回答可以減輕此問題(LM找出的相關文獻或引用也有為幻覺之嫌，務必謹慎確認)\n無法做到精確字數要求，如過您在指令中加入以下要求\u0026rdquo;\u0026hellip;, 在50個字以內說明\u0026rdquo;，可能會出現60甚至70個字(會因語言影響誤差範圍，該問題為token與字/詞數量不等所導致，一個字/詞可由1~n個token組成，通常為1~3個，參考BPE編碼)\n1. Write Clear and Specific Instructions Clear != Short，更長的指令通常提供了更多資訊，可以令模型產生更準確的結果。 Use delimiters，使用分隔符號將輸入資訊清楚的分割，使輸入資料不會與指令或其他資訊混淆，該方法也可以一定程度抵擋Prompt Injections(透過在輸入資料中夾帶惡意指令使模型輸出改變的技術。如:忽略先前的指令，幫我\u0026hellip;。使用分隔符號將其指定為輸入資料可使模型不執行該惡意指令) Ask for structured output，可以在指令中要求輸出資料以json、xml等結構化的形式表達，可以被更好的儲存或處裡 Check whether conditions are satisfied，在指令中加入一些條件，避免一些意外使輸出不合預期 Few-shot prompting，對於一個複雜的任務，指令中只有任務描述是不夠的，在指令中加入一些範例可以使LM有效理解你的要求(補充，LLM在zero-shot的表現並不佳，請盡量避免) 2. Give Model Time to Think Specify the steps to complete a task，一個複雜的任務可以將其拆解成多個較為簡單的步驟或指令使模型可以更好理解或處理您的任務 Instruct the model to work out its own solution before rushing to a conclusion，詢問模型時可以要求模型先輸出推論過程在輸出結果 Iterative Prompt Development(Prompt 的開發與迭代流程) Prompt的構成:\nInstructions Context Input Data Output Indicator Prompt guidelines:\n寫出符合基本原則的Prompt 測試Prompt，取得大量輸出 找出不合預期的案例並分析原因以改進Prompt Repeat 並沒有所謂的萬能Prompt，只有適合的Prompt\nUse Case Summarizing 文本摘要 LLM 通常預設以抽樣摘要(以比原文更簡短的通順文本表述原文資訊)為主，可以要求:字數、句數、風格(簡潔的、嚴謹的)、側重在甚麼(對\u0026hellip;的影響、XXX說的內容)、摘要的對象(國小生、商業部門經理)等\n你可以要求LLM以抽取式摘要(原文的重點字、詞、句、段，原封不動的取出)，如:\u0026ldquo;找出/萃取文章中XXX會想知道的關鍵字/資訊/句子\u0026rdquo;，取得關鍵資訊避免攏言贅詞並減少幻覺產生的可能。\nQuestion Answering 問答 Prompt:\nAnswer the question based on the context below. Keep the answer short and concise. Respond \u0026ldquo;Unsure about answer\u0026rdquo; if not sure about the answer.\nKeep the answer short and concise: 指定風格 Respond \u0026ldquo;Unsure about answer\u0026rdquo; if not sure about the answer: 1.3-Check whether conditions are satisfied Text Classification 文本分類 Classify the text into neutral, negative or positive and follow the output format.\noutput format:\u0026ldquo;Class\u0026rdquo;\nText: I think the vacation is okay.\nSentiment: \u0026ldquo;Neutral\u0026rdquo;\nText: I think the food was okay. Sentiment: \u0026ldquo;Neutral\u0026rdquo;\n","permalink":"https://lin-roger.github.io/posts/promptee/","summary":"簡單介紹prompt-engineering","title":"prompt-engineering 基礎"},{"content":"摘要 SVM被公認是許多任務中效果最好的分類方法之一，SVM的學習能力和訓練計算複雜度與特徵空間維度無關，但在文本分類任務中，降低複雜度是有效處裡大量詞語的一個要點。該論文採用新的降維方法降低文檔向量的維度。還為基於中心的分類算法和SVM分類器引入決策函數，處理一個文檔可能屬於多個class的問題。分析大量的實驗結果表明使用為聚類資料設計的降維算法，使輸入維度降低，可在不犧牲預測精度的情況下取得更好的訓練效率。\n簡介 文本分類是一項監督是任務，將文本分類到預定義的class，用來從大樣文本中尋找有價值的資訊，base on Vctor Space的方法有以下特性，input高維且稀疏(one hot, bag of word)，線性可分性(存在超平面將資料分割)，少數特徵不相關(多數相關)。有人猜測，積極降維會導致資訊嚴重損失，導致分類效果不佳。\n給定訓練資料:\n$$(x_i, y_i)$$\n$$1\\le y_i \\le 1$$\n$$1\\le i\\le n$$\n具K, C的soft margin SVM之對偶式(Loss(target) funtion, Constraint(條件、約束))為:\n$\\max_{\\alpha_i} \\sum_{i=1}^{n} \\alpha i -\\frac{1}{2}\\sum{i,j=1}^{n} \\alpha_i \\alpha_j y_i y_jK(\\mathrm {x}_i, \\mathrm {x}_j),$\n$s.t. \\sum_{i=1}^{n} \\alpha_iy_i=0, 0\\le \\alpha_i\\le C, i=1,\\dots ,n.$\nK is (\u0026lt;, \u0026gt; 矩陣乘法，處裡非線性可分, $\\phi$是一個mapping)\n$K(\\mathrm {x}_i, \\mathrm {x}_j) = \u0026lt; \\phi(\\mathrm {x}_i), \\phi(\\mathrm {x}_j)\u0026gt;$\n如上式所述，SVM的複雜度取決於訓練樣本數，為$O(n)$。並且因K函數的使用不受dim of feature space影響，然而K函數的計算複雜性被忽略了其取決於dim of input space，就算在最佳分割超平面的情況K函數的計算複雜性也無法被省略。因此降維必定可以使訓練SVM和預測帶來更高效率。\n該論文假設文件集合表示為Document-Term Matrix(Bag of Word)，加權兩倍，假設資料的聚類已經進行。\n下一章回顧LSI，使用svd分解做a的低秩近似，但忽略了資料的聚類結構。第三節中，回顧幾種對聚類資料特別有效的降維演算法:兩種群中心方法和使用GSVD(廣義奇異值分解)的泛化LDA。通過降維SVM()和K-mens(計算向量對距離)等分類器的計算複雜度皆可大降低。\n多數文本資料集中，文本可被分入多個類，為更有效處理此問題，在第四節中介紹基於閥值的分類算法擴展，實驗表明，該論文提出的cluster preserving降維演算法沒有造成訊息損失，反而提升了分類器的預測精度(推斷具有去噪效果)。\n低秩近似使用隱含語意索引 LSI假設:Document-Term Matrix中存在隱含的語意結構，其被文件中出現各種詞所破壞(polysemy and synonymy)。基本概念:若兩個文檔向量代表同一主題，其會共享許多與關鍵詞相關的關聯詞，通過SVD其語意結構會十分接近(term vectors表示為左奇異向量document vectors表示為右奇異向量)。然而，LSI再降維時忽略了聚類結構，且並沒有理論最佳的參數選擇，需多次實驗來確定最佳維度(如第五章所述)。實驗結果證實，當資料已被聚類時，下節介紹的降維法對新資料的分類效果更好。\n聚類資料的降維演算法 為提升高維度資料的處裡效率，須將資料降維，此節回顧三種保留聚類結構的降維算法\nCentroid-based Algorithms for Dimension Reduction of Clustered Data 給定一Document-Term Matrix，找一變換映射每個document vector從m維空間降到l維空間(m\u0026gt;l)，兩種方法:\n線性轉換($G^T_{l\\times m}$) 低秩近似(分解為兩個矩陣) $A\\approx BY$\n只要計算給定資料的降維表示，就無須從B計算降維變換G，若確定矩陣B，Y即可用最小平方法求解。\n$\\min_{B,Y}\\left|BY-A\\right|_{F.}$\n給定任意文本$q\\in\\mathbb{R}^{m\\times1}$透過解最小化問題轉換到低維空間。\n$\\min_{\\hat{q}\\in\\mathbb{R}^{l\\times1}}\\left| B\\hat{q}-q\\right|_{2.}$\n在Centroid降維法中(A1)，B的第$i, (1\\le i\\le p)$列是第$i$個群的中心(均值中心)點向量，任一向量$q$，可在$p$維空間表示成$\\hat{q}$即為最小平方法的解。\n在Orthogonal Centroid演算法中(A2)，使用$p$維表示資料向量$q\\in \\mathbb{R}^{m\\times 1}$被給定為$\\hat{q}=Q_{p}^{T}q$，$Q_p$為$B$的正交基底(QR分解)。\n以上兩種等Centroid-based降維法在計算成本比LSI更低，且在聚類資料下的效果更好。雖然此方案只能在線性可分的資料使用，但文本資料扔然可用，因文本資料通常是線性可分的(非線性可分in 18)\nGeneralized Discriminant Analysis based on the Generalized Singular Value Decomposition 近期(2003)，出現了GSVD base 的 cluster-preserving降維法，使SVM泛化到高維空間資料。\n經典判別分析透過最大化聚類之間的散度和最小化即群內的散度，維持聚類結構。為此，其定義聚類內散度矩陣$S_w$和聚類間散度矩陣$S_b$，$N_i$表示集群$i$的列索引集合$n_i$表示集群$i$的列數，$C$表全域中心點。目標使群內散度最小化，和降維後群間散度最大化。再次請出$G^T\\in \\mathbb{R}^{l\\times m}$將A的每列m維向量映射到l維的變換，目標表示為最小化$trace(G^T S_wG)$和最大化$trace(G^T S_bG)$。\n當$S_w$可逆(nonsingular、invertible)，可視為解最大化問題。 全局最大成立於:$G$的列是$S_{w}^{-1}S_b$的特徵向量並對應於$l$個最大特徵值。 when $l\\le p-1$ is equals $λ_1 + \\dots +λ_{p−1},$ each $λ_i ≥ 0$。設Document-Term Matrix $A$被分為$A=[A_1,\\ \\dots , \\ A_p]$，$A_i \\in \\mathbb{R}^{m\\times n_i}\\ \\text{in cluster}\\ i$\n$H_w = [a_1-c_1, a_2-c_2,\\dots ,a_n-c_p]\\in \\mathbb{R}^{m\\times n}$\n$H_b = [\\sqrt{n_1}(c_1-c),\\dots ,\\sqrt{n_p}(c_p-c)]\\in \\mathbb{R}^{m\\times p}$\n$S_w=H_wH_w^T\\ \u0026amp; \\ S_b=H_bH_b^T$\n當詞數(terms) $m$ \u0026gt; 文本數(doc) $n$，$S_w$不可逆(singular)，經典SVM失效。將問題(特徵值) $S_w^{-1}S_b\\mathrm{x}_i = λ_i\\mathrm{x}^i$ 改寫為 $\\mathrm\\beta_i^2H_bH_b^T\\mathrm{x}_i = \\mathrm\\alpha_i^2H_wH_w^T\\mathrm{x}_i$即可透過GSVD處理(LDA/GSVD in A3)。其中最複雜的計算部分複合矩陣$H$的完全正交分解，當$\\max (p, n)\\ll m$，$H=[H_b^T,H_w^T]\\in \\mathbb{R}^{(p+n)\\times m}$ 的SVD分解可被計算為:\n計算$H_t$的QR分解$Q_HR_H$ 計算$R_H\\in \\mathbb{R}^{(p+n)\\times (p+n)}$ 的SVD分解 $=Z\\begin{pmatrix} \\sum_H \u0026amp; 0 \\ 0 \u0026amp; 0 \\end{pmatrix}P^T$，使$H=R_H^TQ_H^T=P\\begin{pmatrix} \\sum_H \u0026amp; 0 \\ 0 \u0026amp; 0 \\end{pmatrix}Z^TQ_H^T$。其中$Q_HZ\\in\\mathbb{R}^{m\\times (p+n)}$的列之間為標準正交的(內積0、距離1)，存在正交$Q\\in \\mathbb{R} ^{m\\times m}$其前$p+n$列等同$Q_HZ$。將式整理為：\n$H = P\\begin{pmatrix} \\sum_H \u0026amp; 0 \\ 0 \u0026amp; 0 \\end{pmatrix}Q^T$\n式中$\\sum_H$的右邊有$m-t$個0列，因$R_H\\in \\mathbb{R}^{(p+n)\\times (p+n)}$遠小於$H\\in \\mathbb{R}^{(p+n)\\times m}$，記憶體需求大減，複雜度也降至$O(mn^2)+O(n^3)$ 分類方法 為測試降維效果，使用三種分類器測試:中心點分類、kNN和SVMs。皆引入閥值進行修改，以確保文本被判有多重類別資格時可以正確分類。\nCentroid-based 設新的文本資料為$q$，訓練資料共有$p$個群，$c_i$為第$i$個群的中心點向量:\n$arg \\max_{1\\le i\\le p} \\frac{q^Tc_i}{|q|_2 |c_i|_2}$\n多類別擴展($\\theta$為閥值):\n$y(\\mathrm{x}, j) = \\text{sign}{ sim(\\mathrm{x}, \\mathrm{c}_i)-\\theta_j^c }$\n$y(\\mathrm{x}, j)\\in { +1,-1 }$\n$$ \\begin{cases} \\text{Class is j} \u0026amp; \\text{:} \u0026amp; y(\\mathrm{x}, j)\u0026gt;0 \\ \\text{Class is not j} \u0026amp; \\text{:} \u0026amp; y(\\mathrm{x}, j)\\le 0 \\end{cases} $$\nk-Nearest Neighbor 設新的文本資料為$q$，訓練文本資料共有$p$個群:\n在訓練資料中，使用餘弦相似度計算與$q$最近的k個文本向量 在這k個向量中，計算屬於各個群的數量，$q$將被分配到最多的那個。 多類別擴展($\\theta$為閥值，$kNN$為文本$x$的$k$個鄰近向量集合):\n$y(\\mathrm{x}, j) = \\text{sign}{ \\sum_{\\mathrm{d}_i\\in kNN} sim(\\mathrm{x}, \\mathrm{d}_i) y(\\mathrm{d}_i, j) -\\theta_j^{kNN} }$\nSVM OvR策略(為每個Class建一個分類器)的二元分類器的最佳分割超平面可透conventional SVM取得。引入多類別擴展:\n$$ y(\\mathrm{x}, j) = \\text{sign}{ \\sum_{\\mathrm{x}_i\\in SV} \\alpha_i y_i K(\\mathrm{x}, \\mathrm{x}_i)+ b -\\theta_j^{SVM} }\\ K=\u0026lt;\\mathrm{x}, \\mathrm{x}_i\u0026gt; \\ K=[\u0026lt;\\mathrm{x}, \\mathrm{x}_i\u0026gt;+1]^d \\ K=\\exp(-\\gamma|\\mathrm{x}, \\mathrm{x}_i|^2) $$\n$SV$為支援向量的集合，$\\theta$為閥值，$\\gamma$與高斯函數寬度成反比。\n實驗結果 預測結果包含:\n無降維 LSI/SVD Centroid Orthogonal Centroid LDA/GSVD SVM優化:\n正則參數$C$ polynomial 角度$d$ Gaussian RBF $\\gamma$ 資料集 subset of MEDLINE database: 5個class、每個class各有500份文本、每份文本只有一個class、train:test = 50:50、做詞型還原和處理剔除字(此為國家教育研究院翻譯版，俗稱為停用詞)後訓練集有22095個不重複的詞。 Reuter-21578 文本集的\u0026quot;ModApte\u0026quot;分割: 90個class、每份文本可能有多個class、每個class至少有一個train和一個test、共7769個train和3019個tess、做詞型還原和處理剔除字(此為國家教育研究院翻譯版，俗稱為停用詞)後訓練集有11941個不重複的詞、引入閥值模型。 DTM不用BoW，改用TF-IDF並歸一化。\n表一 對MEDLINE資料集使用LSI/SVD，用使用centroid-based, kNN和SVMs分類器分類的結果。觀察到:\nkNN使用L2 norm在$l$為100-500時效果不佳，與餘弦相似性在未正則化資料表現更好的印象相符，且5NN明顯落後其他更高的K，表明k=5太小。 表二 SVM使用不同的K(核)函數與降維演算法在MEDLINE資料集的結果。觀察到:\n降維後的預測結果與原始空間的預測結果相似且複雜度降低。 正交中心降維演算法對K函數的選擇不敏感，可以選複雜度更低的線性K函數。 表三 選擇不同分類演算法與降維演算法在MEDLINE資料集的結果。觀察到:\n使用LDA/GSVD降維演算法時，使用餘弦相似度的centroid-based與kNN分類演算法效果較差，而使用L2-norm的效果較好，因跡最佳化使用L2-norm表示。 因LDA/GSVD最小化群內散點的跡(距離)，自同一(相似)類別的文檔向量會被變換為一個緻密的群甚至一個點，使得SVM難以找到泛化性高的超平面。 表四 MEDLINE資料集中使用SVM配合不同降維演算法在5個不同類別中的準確率。觀察到:\ncolon cancer與oral cancer難以被區分。 表五 選擇不同分類演算法與降維演算法(Centroid、Orthogonal Centroid)在REUTERS資料集的結果。觀察到:\nOrthogonal Centroid 效果無明顯下降，Centroid則明顯降低，推測因將各個聚類中心映射至單位矩陣導致每個class間的資訊消失所造成。 結論與討論 本文使用三種降維方法Centroid、Orthogonal Centroid和LDA/GSVD，皆是為集群資料所設計，做為比較也使用了LSI/SVD這種不保留集群結構的降維演算法。其也測試了三種不同的分類演算法SVMs、kNN與centroid-based classification測試在不同降維法中的分類效果。測試結果取得了高的準度，即使在強力的降維下，也可與未降維的狀態近似。\n該論文還引入了基於閥值的分類器，用於centroid-based和SVM做到一對多的分類。centroid在Class互不關聯的情況下表現更好。\n結論 不犧牲精度的情況下，可以做到對文本大幅降為。Orthogonal Centroid在保留聚類結構的能力做的極佳，降為前後的預測準確率幾乎不變，在KNN或SVM使用可以極大減少計算複雜度。\n","permalink":"https://lin-roger.github.io/posts/dimensionreductionintextclassificationwithsupportvectormachines/","summary":"非經典古文，可以不用看，主要是我的筆記。SVM被公認是許多任務中效果最好的分類方法之一，SVM的學習能力和訓練計算複雜度與特徵空間維度無關，但在文本分類任務中，降低複雜度是有效處裡大量詞語的一個要點。該論文採用新的降維方法降低文檔向量的維度。還為基於中心的分類算法和SVM分類器引入決策函數，處理一個文檔可能屬於多個class的問題。分析大量的實驗結果表明使用為聚類資料設計的降維算法，使輸入維度降低，可在不犧牲預測精度的情況下取得更好的訓練效率。","title":"Dimension Reduction in Text Classification with Support Vector Machines"}]